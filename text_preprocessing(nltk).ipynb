{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ace63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2724fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/spam.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\FAZIL K\n",
      "[nltk_data]     FAAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\FAZIL K\n",
      "[nltk_data]     FAAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\FAZIL K\n",
      "[nltk_data]     FAAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\FAZIL K FAAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\FAZIL K\n",
      "[nltk_data]     FAAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\FAZIL K\n",
      "[nltk_data]     FAAZI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize , sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer , PorterStemmer , SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "porterstemmer = PorterStemmer()\n",
    "snowballstemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    sent_tokens = sent_tokenize(text)\n",
    "    filtered_tokens = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    porterstemmer_tokens = [porterstemmer.stem(word.lower()) for word in filtered_tokens]\n",
    "    snowballstemmer_tokens = [snowballstemmer.stem(word.lower()) for word in filtered_tokens]\n",
    "    lemmatizer_tokens = [lemmatizer.lemmatize(word.lower()) for word in filtered_tokens]\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"original_text\": text,\n",
    "        \"word_tokens\": word_tokens,\n",
    "        \"sent_tokens\": sent_tokens,\n",
    "        \"filtered_tokens\": filtered_tokens,\n",
    "        \"porterstemmer_tokens\": porterstemmer_tokens,\n",
    "        \"snowballstemmer_tokens\": snowballstemmer_tokens,\n",
    "        \"lemmatizer_tokens\": lemmatizer_tokens,\n",
    "    }\n",
    "\n",
    "results = df['v2'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834462b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Go', 'VB'), ('jurong', 'JJ'), ('point', 'NN'), (',', ','), ('crazy', 'JJ'), ('..', 'NNP'), ('Available', 'NNP'), ('bugis', 'NN'), ('n', 'RB'), ('great', 'JJ'), ('world', 'NN'), ('la', 'NN'), ('e', 'FW'), ('buffet', 'NN'), ('...', ':'), ('Cine', 'NNP'), ('got', 'VBD'), ('amore', 'RB'), ('wat', 'JJ'), ('...', ':'), ('Ok', 'NNP'), ('lar', 'NN'), ('...', ':'), ('Joking', 'NNP'), ('wif', 'WRB')]\n",
      "(S\n",
      "  Go/VB\n",
      "  jurong/JJ\n",
      "  point/NN\n",
      "  ,/,\n",
      "  crazy/JJ\n",
      "  ../NNP\n",
      "  Available/NNP\n",
      "  bugis/NN\n",
      "  n/RB\n",
      "  great/JJ\n",
      "  world/NN\n",
      "  la/NN\n",
      "  e/FW\n",
      "  buffet/NN\n",
      "  .../:\n",
      "  (PERSON Cine/NNP)\n",
      "  got/VBD\n",
      "  amore/RB\n",
      "  wat/JJ\n",
      "  .../:\n",
      "  Ok/NNP\n",
      "  lar/NN\n",
      "  .../:\n",
      "  Joking/NNP\n",
      "  wif/WRB\n",
      "  u/JJ\n",
      "  oni/NN\n",
      "  .../:\n",
      "  Free/JJ\n",
      "  entry/NN\n",
      "  2/CD\n",
      "  wkly/JJ\n",
      "  comp/NN\n",
      "  win/VBP\n",
      "  FA/NNP\n",
      "  Cup/NNP\n",
      "  final/JJ\n",
      "  tkts/NN\n",
      "  21st/CD\n",
      "  May/NNP\n",
      "  2005/CD\n",
      "  ./.\n",
      "  (PERSON Text/NNP)\n",
      "  FA/NNP\n",
      "  87121/CD\n",
      "  receive/JJ\n",
      "  entry/NN\n",
      "  question/NN\n",
      "  (/(\n",
      "  std/JJ\n",
      "  txt/NN\n",
      "  rate/NN\n",
      "  )/)\n",
      "  &/CC\n",
      "  C/NNP\n",
      "  's/POS\n",
      "  apply/VBP\n",
      "  08452810075over18/CD\n",
      "  's/POS\n",
      "  U/JJ\n",
      "  dun/NNS\n",
      "  say/VBP\n",
      "  early/JJ\n",
      "  hor/NN\n",
      "  .../:\n",
      "  U/NNP\n",
      "  c/VBP\n",
      "  already/RB\n",
      "  say/VBP\n",
      "  .../:\n",
      "  Nah/VBP\n",
      "  n't/RB\n",
      "  think/VB\n",
      "  goes/VBZ\n",
      "  usf/RB\n",
      "  ,/,\n",
      "  lives/VBZ\n",
      "  around/IN\n",
      "  though/IN\n",
      "  (ORGANIZATION FreeMsg/NNP)\n",
      "  Hey/NNP\n",
      "  darling/VBG\n",
      "  's/POS\n",
      "  3/CD\n",
      "  week/NN\n",
      "  's/POS\n",
      "  word/NN\n",
      "  back/RB\n",
      "  !/.\n",
      "  'd/MD\n",
      "  like/VB\n",
      "  fun/NN\n",
      "  still/RB\n",
      "  ?/.\n",
      "  Tb/NNP\n",
      "  ok/NN\n",
      "  !/.\n",
      "  (ORGANIZATION XxX/NNP)\n",
      "  std/VBD\n",
      "  chgs/JJ\n",
      "  send/NN\n",
      "  ,/,\n",
      "  å£1.50/NNP\n",
      "  rcv/VBD\n",
      "  Even/RB\n",
      "  brother/RBR\n",
      "  like/IN\n",
      "  speak/NN\n",
      "  ./.\n",
      "  treat/NN\n",
      "  like/IN\n",
      "  aids/NNS\n",
      "  patent/NN\n",
      "  ./.\n",
      "  per/IN\n",
      "  request/NN\n",
      "  'Melle/CD\n",
      "  (GPE Melle/NNP)\n",
      "  (/(\n",
      "  (ORGANIZATION Oru/NNP Minnaminunginte/NNP Nurungu/NNP Vettam/NNP)\n",
      "  )/)\n",
      "  '/''\n",
      "  set/VBN\n",
      "  callertune/NN\n",
      "  (GPE Callers/NNP)\n",
      "  ./.\n",
      "  (PERSON Press/NNP)\n",
      "  */VBD\n",
      "  9/CD\n",
      "  copy/NN\n",
      "  friends/NNS\n",
      "  (PERSON Callertune/NNP WINNER/NNP)\n",
      "  !/.\n",
      "  !/.\n",
      "  valued/VBN\n",
      "  network/NN\n",
      "  customer/NN\n",
      "  selected/VBN\n",
      "  receivea/NN\n",
      "  å£900/NNP\n",
      "  prize/VB\n",
      "  reward/NN\n",
      "  !/.\n",
      "  claim/NN\n",
      "  call/NN\n",
      "  09061701461/CD\n",
      "  ./.\n",
      "  (PERSON Claim/NNP)\n",
      "  code/NN\n",
      "  (ORGANIZATION KL341/NNP)\n",
      "  ./.\n",
      "  Valid/NNP\n",
      "  12/CD\n",
      "  hours/NNS\n",
      "  ./.\n",
      "  mobile/JJ\n",
      "  11/CD\n",
      "  months/NNS\n",
      "  ?/.\n",
      "  U/NNP\n",
      "  R/NNP\n",
      "  entitled/VBD\n",
      "  (ORGANIZATION Update/NNP)\n",
      "  latest/JJS\n",
      "  colour/NN\n",
      "  mobiles/NNS\n",
      "  camera/VBP\n",
      "  (PERSON Free/JJ)\n",
      "  !/.\n",
      "  (PERSON Call/NNP Mobile/NNP Update/NNP Co/NNP)\n",
      "  FREE/NNP\n",
      "  08002986030/CD\n",
      "  'm/VBP\n",
      "  gon/JJ\n",
      "  na/TO\n",
      "  home/NN\n",
      "  soon/RB\n",
      "  n't/RB\n",
      "  want/VB\n",
      "  talk/NN\n",
      "  stuff/NN\n",
      "  anymore/RB\n",
      "  tonight/NN\n",
      "  ,/,\n",
      "  k/VB\n",
      "  ?/.\n",
      "  've/VBP\n",
      "  cried/VBN\n",
      "  enough/JJ\n",
      "  today/NN\n",
      "  ./.\n",
      "  SIX/NNP\n",
      "  chances/NNS\n",
      "  win/VBP\n",
      "  (ORGANIZATION CASH/NNP)\n",
      "  !/.\n",
      "  100/CD\n",
      "  20,000/CD\n",
      "  pounds/NNS\n",
      "  txt/JJ\n",
      "  >/NNP\n",
      "  CSH11/NNP\n",
      "  send/VBP\n",
      "  87575/CD\n",
      "  ./.\n",
      "  Cost/NN\n",
      "  150p/day/CD\n",
      "  ,/,\n",
      "  6days/CD\n",
      "  ,/,\n",
      "  16+/CD\n",
      "  TsandCs/NNP\n",
      "  apply/RB\n",
      "  (PERSON Reply/NNP)\n",
      "  HL/NNP\n",
      "  4/CD\n",
      "  info/NN\n",
      "  (ORGANIZATION URGENT/NNP)\n",
      "  !/.\n",
      "  1/CD\n",
      "  week/NN\n",
      "  (ORGANIZATION FREE/NNP)\n",
      "  membership/NN\n",
      "  å£100,000/NNP\n",
      "  Prize/NNP\n",
      "  (PERSON Jackpot/NNP)\n",
      "  !/.\n",
      "  Txt/NNP\n",
      "  word/NN\n",
      "  :/:\n",
      "  CLAIM/NN\n",
      "  :/:\n",
      "  81010/CD\n",
      "  &/CC\n",
      "  C/NNP\n",
      "  www.dbuk.net/NN\n",
      "  (ORGANIZATION LCCLTD/NNP)\n",
      "  POBOX/NNP\n",
      "  4403LDNW1A7RW18/CD\n",
      "  've/VBP\n",
      "  searching/VBG\n",
      "  right/JJ\n",
      "  words/NNS\n",
      "  thank/VBD\n",
      "  breather/RB\n",
      "  ./.\n",
      "  promise/VB\n",
      "  wont/JJ\n",
      "  take/VB\n",
      "  help/NN\n",
      "  granted/VBN\n",
      "  fulfil/JJ\n",
      "  promise/NN\n",
      "  ./.\n",
      "  wonderful/JJ\n",
      "  blessing/NN\n",
      "  times/NNS\n",
      "  ./.\n",
      "  (ORGANIZATION DATE/NNP)\n",
      "  SUNDAY/NNP\n",
      "  !/.\n",
      "  !/.\n",
      "  XXXMobileMovieClub/NN\n",
      "  :/:\n",
      "  use/NN\n",
      "  credit/NN\n",
      "  ,/,\n",
      "  click/JJ\n",
      "  (ORGANIZATION WAP/NNP)\n",
      "  link/NN\n",
      "  next/IN\n",
      "  txt/JJ\n",
      "  message/NN\n",
      "  click/NN\n",
      "  >/NNP\n",
      "  >/NNP\n",
      "  http/NN\n",
      "  :/:\n",
      "  //wap/NN\n",
      "  ./.\n",
      "  xxxmobilemovieclub.com/VB\n",
      "  ?/.\n",
      "  n=QJKGIGHJJGCBL/JJ\n",
      "  Oh/NNP\n",
      "  k/NN\n",
      "  .../:\n",
      "  'm/VBP\n",
      "  watching/VBG\n",
      "  :/:\n",
      "  )/)\n",
      "  Eh/NNP\n",
      "  u/JJ\n",
      "  remember/VB\n",
      "  2/CD\n",
      "  spell/NN\n",
      "  name/NN\n",
      "  .../:\n",
      "  Yes/UH\n",
      "  ./.\n",
      "  v/JJ\n",
      "  naughty/JJ\n",
      "  make/NN\n",
      "  v/NN\n",
      "  wet/NN\n",
      "  ./.\n",
      "  (PERSON Fine/NNP)\n",
      "  thatåÕs/JJ\n",
      "  way/NN\n",
      "  u/JJ\n",
      "  feel/NN\n",
      "  ./.\n",
      "  ThatåÕs/NNP\n",
      "  way/NN\n",
      "  gota/NN\n",
      "  b/NN\n",
      "  (GPE England/NNP)\n",
      "  v/NN\n",
      "  (GPE Macedonia/NNP)\n",
      "  -/:\n",
      "  dont/NN\n",
      "  miss/JJ\n",
      "  goals/team/NN\n",
      "  news/NN\n",
      "  ./.\n",
      "  Txt/NNP\n",
      "  ur/JJ\n",
      "  national/JJ\n",
      "  team/NN\n",
      "  87077/CD\n",
      "  eg/NN\n",
      "  (ORGANIZATION ENGLAND/NNP)\n",
      "  87077/CD\n",
      "  Try/NNP\n",
      "  :/:\n",
      "  WALES/NNP\n",
      "  ,/,\n",
      "  (ORGANIZATION SCOTLAND/NNP)\n",
      "  4txt/Ì¼1.20/CD\n",
      "  POBOXox36504W45WQ/NNP\n",
      "  16+/CD\n",
      "  seriously/RB\n",
      "  spell/VB\n",
      "  name/NN\n",
      "  ?/.\n",
      "  IÛ÷m/NNP\n",
      "  going/VBG\n",
      "  try/RB\n",
      "  2/CD\n",
      "  months/NNS\n",
      "  ha/JJ\n",
      "  ha/NN\n",
      "  joking/VBG\n",
      "  Ì_/JJ\n",
      "  pay/NN\n",
      "  first/RB\n",
      "  lar/JJ\n",
      "  .../:\n",
      "  da/NN\n",
      "  stock/NN\n",
      "  comin/NN\n",
      "  .../:\n",
      "  Aft/NNP\n",
      "  finish/VB\n",
      "  lunch/NN\n",
      "  go/VBP\n",
      "  str/JJ\n",
      "  lor/NN\n",
      "  ./.\n",
      "  Ard/$\n",
      "  3/CD\n",
      "  smth/JJ\n",
      "  lor/NN\n",
      "  ./.\n",
      "  U/NNP\n",
      "  finish/JJ\n",
      "  ur/JJ\n",
      "  lunch/NN\n",
      "  already/RB\n",
      "  ?/.\n",
      "  Ffffffffff/NNP\n",
      "  ./.\n",
      "  (PERSON Alright/NNP)\n",
      "  way/NN\n",
      "  meet/NN\n",
      "  sooner/NN\n",
      "  ?/.\n",
      "  forced/VBN\n",
      "  eat/NN\n",
      "  slice/NN\n",
      "  ./.\n",
      "  'm/VBP\n",
      "  really/RB\n",
      "  hungry/JJ\n",
      "  tho/NN\n",
      "  ./.\n",
      "  sucks/NNS\n",
      "  ./.\n",
      "  (PERSON Mark/NNP)\n",
      "  getting/VBG\n",
      "  worried/VBN\n",
      "  ./.\n",
      "  knows/NNS\n",
      "  'm/VBP\n",
      "  sick/JJ\n",
      "  turn/NN\n",
      "  pizza/NN\n",
      "  ./.\n",
      "  (PERSON Lol/NNP Lol/NNP)\n",
      "  always/RB\n",
      "  convincing/VBG\n",
      "  ./.\n",
      "  catch/VB\n",
      "  bus/NN\n",
      "  ?/.\n",
      "  frying/VBG\n",
      "  egg/NN\n",
      "  ?/.\n",
      "  make/VB\n",
      "  tea/NN\n",
      "  ?/.\n",
      "  eating/VBG\n",
      "  mom/NN\n",
      "  's/POS\n",
      "  left/NN\n",
      "  dinner/NN\n",
      "  ?/.\n",
      "  feel/VB\n",
      "  (PERSON Love/NNP)\n",
      "  ?/.\n",
      "  'm/VBP\n",
      "  back/RB\n",
      "  &/CC\n",
      "  amp/NN\n",
      "  ;/:\n",
      "  're/VBP\n",
      "  packing/VBG\n",
      "  car/NN\n",
      "  ,/,\n",
      "  'll/MD\n",
      "  let/VB\n",
      "  know/VB\n",
      "  's/POS\n",
      "  room/NN\n",
      "  Ahhh/NNP\n",
      "  ./.\n",
      "  Work/NNP\n",
      "  ./.\n",
      "  vaguely/RB\n",
      "  remember/VB\n",
      "  !/.\n",
      "  feel/VB\n",
      "  like/IN\n",
      "  ?/.\n",
      "  Lol/NNP\n",
      "  (PERSON Wait/NNP)\n",
      "  's/POS\n",
      "  still/RB\n",
      "  clear/JJ\n",
      "  ,/,\n",
      "  sure/JJ\n",
      "  sarcastic/NN\n",
      "  's/POS\n",
      "  x/VBP\n",
      "  n't/RB\n",
      "  want/VB\n",
      "  live/JJ\n",
      "  us/PRP\n",
      "  (PERSON Yeah/NNP)\n",
      "  got/VBD\n",
      "  2/CD\n",
      "  v/NN\n",
      "  apologetic/JJ\n",
      "  ./.\n",
      "  n/JJ\n",
      "  fallen/VBN\n",
      "  actin/NNS\n",
      "  like/IN\n",
      "  spoilt/JJ\n",
      "  child/NN\n",
      "  got/VBD\n",
      "  caught/VBN\n",
      "  ./.\n",
      "  Till/VB\n",
      "  2/CD\n",
      "  !/.\n",
      "  wo/MD\n",
      "  n't/RB\n",
      "  go/VB\n",
      "  !/.\n",
      "  badly/RB\n",
      "  cheers/NNS\n",
      "  ./.\n",
      "  ?/.\n",
      "  K/NNP\n",
      "  tell/IN\n",
      "  anything/NN\n",
      "  ./.\n",
      "  fear/NN\n",
      "  fainting/VBG\n",
      "  housework/NN\n",
      "  ?/.\n",
      "  (PERSON Quick/NNP)\n",
      "  cuppa/NN\n",
      "  (GPE Thanks/NNP)\n",
      "  subscription/NN\n",
      "  Ringtone/NNP\n",
      "  UK/NNP\n",
      "  mobile/NN\n",
      "  charged/VBN\n",
      "  å£5/month/JJ\n",
      "  Please/NNP\n",
      "  confirm/NN\n",
      "  replying/VBG\n",
      "  (ORGANIZATION YES/NNP)\n",
      "  ./.\n",
      "  reply/VB\n",
      "  charged/JJ\n",
      "  Yup/NNP\n",
      "  .../:\n",
      "  Ok/NNP\n",
      "  go/VBP\n",
      "  home/NN\n",
      "  look/NN\n",
      "  timings/NNS\n",
      "  msg/VBP\n",
      "  Ì_/NNS\n",
      "  .../:\n",
      "  Xuhui/VBZ\n",
      "  going/VBG\n",
      "  learn/JJ\n",
      "  2nd/CD\n",
      "  may/MD\n",
      "  lesson/VB\n",
      "  8am/CD\n",
      "  Oops/NNP\n",
      "  ,/,\n",
      "  'll/MD\n",
      "  let/VB\n",
      "  know/VB\n",
      "  roommate/VB\n",
      "  's/POS\n",
      "  done/VBN\n",
      "  see/NN\n",
      "  letter/NN\n",
      "  B/NNP\n",
      "  car/NN\n",
      "  Anything/NNP\n",
      "  lor/NN\n",
      "  .../:\n",
      "  U/NNP\n",
      "  decide/VB\n",
      "  .../:\n",
      "  Hello/NNP\n",
      "  !/.\n",
      "  's/POS\n",
      "  saturday/JJ\n",
      "  go/VB\n",
      "  ?/.\n",
      "  texting/VBG\n",
      "  see/NN\n",
      "  'd/MD\n",
      "  decided/VB\n",
      "  anything/NN\n",
      "  tomo/NN\n",
      "  ./.\n",
      "  'm/VBP\n",
      "  trying/VBG\n",
      "  invite/NN\n",
      "  anything/NN\n",
      "  !/.\n",
      "  Pls/NNP\n",
      "  go/VBP\n",
      "  ahead/RB\n",
      "  watts/RB\n",
      "  ./.\n",
      "  wanted/JJ\n",
      "  sure/NN\n",
      "  ./.\n",
      "  great/JJ\n",
      "  weekend/NN\n",
      "  ./.\n",
      "  (PERSON Abiola/NNP)\n",
      "  forget/VB\n",
      "  tell/VB\n",
      "  ?/.\n",
      "  want/NN\n",
      "  ,/,\n",
      "  need/NN\n",
      "  ,/,\n",
      "  crave/VBP\n",
      "  .../:\n",
      "  .../:\n",
      "  love/VB\n",
      "  sweet/JJ\n",
      "  (GPE Arabian/JJ)\n",
      "  steed/NN\n",
      "  .../:\n",
      "  (PERSON Mmmmmm/NNP)\n",
      "  .../:\n",
      "  Yummy/VBZ\n",
      "  07732584351/CD\n",
      "  -/:\n",
      "  (PERSON Rodger/NN Burns/NNP)\n",
      "  -/:\n",
      "  (ORGANIZATION MSG/NNP)\n",
      "  =/NNP\n",
      "  tried/VBD\n",
      "  call/VB\n",
      "  reply/NN\n",
      "  sms/JJ\n",
      "  free/JJ\n",
      "  nokia/NN\n",
      "  mobile/JJ\n",
      "  +/NNP\n",
      "  free/JJ\n",
      "  camcorder/NN\n",
      "  ./.\n",
      "  Please/NNP\n",
      "  call/VB\n",
      "  08000930705/CD\n",
      "  delivery/NN\n",
      "  tomorrow/NN\n",
      "  SEEING/NN\n",
      "  ?/.\n",
      "  Great/JJ\n",
      "  !/.\n",
      "  hope/NN\n",
      "  like/IN\n",
      "  man/NN\n",
      "  well/RB\n",
      "  endowed/VBN\n",
      "  ./.\n",
      "  &/CC\n",
      "  lt/NN\n",
      "  ;/:\n",
      "  #/#\n",
      "  &/CC\n",
      "  gt/NN\n",
      "  ;/:\n",
      "  inches/NNS\n",
      "  .../:\n",
      "  calls/VBZ\n",
      "  ../JJ\n",
      "  messages/NNS\n",
      "  ../VBP\n",
      "  missed/VBN\n",
      "  calls/NNS\n",
      "  n't/RB\n",
      "  get/VB\n",
      "  hep/JJ\n",
      "  b/NN\n",
      "  immunisation/NN\n",
      "  nigeria/NN\n",
      "  ./.\n",
      "  (PERSON Fair/NNP)\n",
      "  enough/RB\n",
      "  ,/,\n",
      "  anything/NN\n",
      "  going/VBG\n",
      "  ?/.\n",
      "  Yeah/UH\n",
      "  hopefully/RB\n",
      "  ,/,\n",
      "  tyler/NN\n",
      "  ca/MD\n",
      "  n't/RB\n",
      "  could/MD\n",
      "  maybe/VB\n",
      "  ask/VB\n",
      "  around/IN\n",
      "  bit/NN\n",
      "  U/VBP\n",
      "  n't/RB\n",
      "  know/VB\n",
      "  stubborn/JJ\n",
      "  ./.\n",
      "  n't/RB\n",
      "  even/RB\n",
      "  want/VB\n",
      "  go/JJ\n",
      "  hospital/NN\n",
      "  ./.\n",
      "  kept/VB\n",
      "  telling/VBG\n",
      "  (PERSON Mark/NNP)\n",
      "  'm/VBP\n",
      "  weak/JJ\n",
      "  sucker/NN\n",
      "  ./.\n",
      "  Hospitals/NNS\n",
      "  weak/JJ\n",
      "  suckers/NNS\n",
      "  ./.\n",
      "  thinked/VBN\n",
      "  ./.\n",
      "  First/JJ\n",
      "  time/NN\n",
      "  saw/JJ\n",
      "  class/NN\n",
      "  ./.\n",
      "  gram/NN\n",
      "  usually/RB\n",
      "  runs/VBZ\n",
      "  like/IN\n",
      "  &/CC\n",
      "  lt/VBP\n",
      "  ;/:\n",
      "  #/#\n",
      "  &/CC\n",
      "  gt/NN\n",
      "  ;/:\n",
      "  ,/,\n",
      "  half/NN\n",
      "  eighth/JJ\n",
      "  smarter/NN\n",
      "  though/IN\n",
      "  gets/VBZ\n",
      "  almost/RB\n",
      "  whole/JJ\n",
      "  second/JJ\n",
      "  gram/NN\n",
      "  &/CC\n",
      "  lt/NN\n",
      "  ;/:\n",
      "  #/#\n",
      "  &/CC\n",
      "  gt/NN\n",
      "  ;/:\n",
      "  K/NNP\n",
      "  fyi/VBZ\n",
      "  x/NNP\n",
      "  ride/RB\n",
      "  early/RB\n",
      "  tomorrow/NN\n",
      "  morning/NN\n",
      "  's/POS\n",
      "  crashing/VBG\n",
      "  place/NN\n",
      "  tonight/NN\n",
      "  Wow/NNP\n",
      "  ./.\n",
      "  never/RB\n",
      "  realized/VBN\n",
      "  embarassed/JJ\n",
      "  accomodations/NNS\n",
      "  ./.\n",
      "  thought/NN\n",
      "  liked/VBD\n",
      "  ,/,\n",
      "  since/IN\n",
      "  best/JJS\n",
      "  could/MD\n",
      "  always/RB\n",
      "  seemed/VB\n",
      "  happy/JJ\n",
      "  \\the/NNP\n",
      "  cave\\/NN\n",
      "  ''/''\n",
      "  ./.\n",
      "  'm/VBP\n",
      "  sorry/JJ\n",
      "  n't/RB\n",
      "  n't/RB\n",
      "  give/VB\n",
      "  ./.\n",
      "  'm/VBP\n",
      "  sorry/JJ\n",
      "  offered/VBN\n",
      "  ./.\n",
      "  'm/VBP\n",
      "  sorry/JJ\n",
      "  room/NN\n",
      "  embarassing/VBG\n",
      "  ./.\n",
      "  ''/''\n",
      "  (ORGANIZATION SMS/NNP)\n",
      "  ./.\n",
      "  ac/NN\n",
      "  (PERSON Sptv/NNP)\n",
      "  :/:\n",
      "  New/NNP\n",
      "  (PERSON Jersey/NNP Devils/NNP Detroit/NNP Red/NNP Wings/NNP)\n",
      "  play/NN\n",
      "  Ice/NNP\n",
      "  Hockey/NNP\n",
      "  ./.\n",
      "  (PERSON Correct/NNP Incorrect/NNP)\n",
      "  ?/.\n",
      "  End/NN\n",
      "  ?/.\n",
      "  Reply/NNP\n",
      "  END/NNP\n",
      "  SPTV/NNP\n",
      "  know/VBP\n",
      "  (PERSON Mallika/NNP Sherawat/NNP)\n",
      "  yesterday/NN\n",
      "  ?/.\n",
      "  Find/NNP\n",
      "  @/NNP\n",
      "  &/CC\n",
      "  lt/NN\n",
      "  ;/:\n",
      "  (ORGANIZATION URL/NNP)\n",
      "  &/CC\n",
      "  gt/NN\n",
      "  ;/:\n",
      "  Congrats/NNP\n",
      "  !/.\n",
      "  1/CD\n",
      "  year/NN\n",
      "  special/JJ\n",
      "  cinema/NN\n",
      "  pass/NN\n",
      "  2/CD\n",
      "  ./.\n",
      "  call/VB\n",
      "  09061209465/CD\n",
      "  !/.\n",
      "  C/NNP\n",
      "  (PERSON Suprman/NNP V/NNP)\n",
      "  ,/,\n",
      "  (PERSON Matrix3/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION StarWars3/NNP)\n",
      "  ,/,\n",
      "  etc/FW\n",
      "  4/CD\n",
      "  FREE/JJ\n",
      "  !/.\n",
      "  bx420-ip4-5we/NN\n",
      "  ./.\n",
      "  150pm/CD\n",
      "  ./.\n",
      "  (PERSON Dont/NNP)\n",
      "  miss/NN\n",
      "  !/.\n",
      "  (PERSON Sorry/NNP)\n",
      "  ,/,\n",
      "  'll/MD\n",
      "  call/VB\n",
      "  later/RB\n",
      "  meeting/NN\n",
      "  ./.\n",
      "  (PERSON Tell/NNP)\n",
      "  reached/VBD\n",
      "  (PERSON Yes/NNP)\n",
      "  ../NNP\n",
      "  gauti/NN\n",
      "  sehwag/NN\n",
      "  odi/JJ\n",
      "  series/NN\n",
      "  ./.\n",
      "  gon/VB\n",
      "  na/TO\n",
      "  pick/VB\n",
      "  $/$\n",
      "  1/CD\n",
      "  burger/NN\n",
      "  way/NN\n",
      "  home/NN\n",
      "  ./.\n",
      "  ca/MD\n",
      "  n't/RB\n",
      "  even/RB\n",
      "  move/VB\n",
      "  ./.\n",
      "  Pain/NNP\n",
      "  killing/VBG\n",
      "  ./.\n",
      "  Ha/NNP\n",
      "  ha/NN\n",
      "  ha/NN\n",
      "  good/JJ\n",
      "  joke/NN\n",
      "  ./.\n",
      "  (PERSON Girls/NNP)\n",
      "  situation/NN\n",
      "  seekers/NNS\n",
      "  ./.\n",
      "  part/NN\n",
      "  checking/VBG\n",
      "  (ORGANIZATION IQ/NNP Sorry/NNP)\n",
      "  roommates/VBZ\n",
      "  took/VBD\n",
      "  forever/RB\n",
      "  ,/,\n",
      "  ok/JJ\n",
      "  come/VBN\n",
      "  ?/.\n",
      "  Ok/NNP\n",
      "  lar/JJ\n",
      "  double/RB\n",
      "  check/NN\n",
      "  wif/NN\n",
      "  da/NN\n",
      "  hair/NN\n",
      "  dresser/NN\n",
      "  already/RB\n",
      "  said/VBD\n",
      "  wun/JJ\n",
      "  cut/NN\n",
      "  v/NN\n",
      "  short/JJ\n",
      "  ./.\n",
      "  said/VBD\n",
      "  cut/JJ\n",
      "  look/NN\n",
      "  nice/RB\n",
      "  ./.\n",
      "  valued/VBN\n",
      "  customer/NN\n",
      "  ,/,\n",
      "  pleased/JJ\n",
      "  advise/NN\n",
      "  following/VBG\n",
      "  recent/JJ\n",
      "  review/NN\n",
      "  Mob/NNP\n",
      "  ./.\n",
      "  awarded/VBD\n",
      "  å£1500/JJ\n",
      "  (PERSON Bonus/NNP Prize/NNP)\n",
      "  ,/,\n",
      "  call/VB\n",
      "  09066364589/CD\n",
      "  Today/NNP\n",
      "  \\song/NNP\n",
      "  dedicated/VBD\n",
      "  day/NN\n",
      "  ../FW\n",
      "  \\/NN\n",
      "  ''/''\n",
      "  song/NN\n",
      "  u/JJ\n",
      "  dedicate/NN\n",
      "  ?/.\n",
      "  Send/NNP\n",
      "  ur/JJ\n",
      "  valuable/JJ\n",
      "  frnds/NNS\n",
      "  first/JJ\n",
      "  rply/NN\n",
      "  .../:\n",
      "  ''/''\n",
      "  Urgent/NNP\n",
      "  UR/NNP\n",
      "  awarded/VBD\n",
      "  complimentary/JJ\n",
      "  trip/NN\n",
      "  (ORGANIZATION EuroDisinc/NNP Trav/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION Aco/NNP)\n",
      "  &/CC\n",
      "  (PERSON Entry41/NNP)\n",
      "  å£1000/NNP\n",
      "  ./.\n",
      "  claim/NN\n",
      "  txt/NN\n",
      "  (ORGANIZATION DIS/NNP)\n",
      "  87121/CD\n",
      "  18+6/CD\n",
      "  */NN\n",
      "  å£1.50/NNP\n",
      "  (/(\n",
      "  (ORGANIZATION moreFrmMob/NN)\n",
      "  ./.\n",
      "  ShrAcomOrSglSuplt/NNP\n",
      "  )/)\n",
      "  10/CD\n",
      "  ,/,\n",
      "  (ORGANIZATION LS1/NNP)\n",
      "  3AJ/CD\n",
      "  hear/JJ\n",
      "  new/JJ\n",
      "  \\Divorce/NN\n",
      "  Barbie\\/NNP\n",
      "  ''/''\n",
      "  ?/.\n",
      "  comes/VBZ\n",
      "  (PERSON Ken/NNP)\n",
      "  's/POS)\n"
     ]
    }
   ],
   "source": [
    "processed_df = pd.DataFrame(results.tolist())\n",
    "processed_df.head()\n",
    "\n",
    "pos_tokens = processed_df['filtered_tokens'].explode().dropna().tolist()\n",
    "pos_tokens = pos_tokens[:1000]\n",
    "pos_tag_words = nltk.pos_tag(pos_tokens)\n",
    "ner_words = nltk.ne_chunk(pos_tag_words)\n",
    "\n",
    "print(pos_tag_words[:25])\n",
    "print(ner_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e48a17",
   "metadata": {},
   "source": [
    "**Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d15bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      "['00' '000' '000pes' ... 'ûïharry' 'ûò' 'ûówell']\n",
      "{'one_hot': array([[1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 1., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 1., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 1.]]), 'bow': <5572x8117 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 47921 stored elements in Compressed Sparse Row format>, 'tfidf': <5572x8117 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 47921 stored elements in Compressed Sparse Row format>}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "lemmas = processed_df['lemmatizer_tokens'].explode().dropna().tolist()\n",
    "vocab = sorted(set(lemmas))\n",
    "\n",
    "vocab_reshaped = np.array(vocab).reshape(-1, 1)\n",
    "one_hot = OneHotEncoder(sparse_output=False)\n",
    "one_hot_matrix = one_hot.fit_transform(vocab_reshaped)\n",
    "\n",
    "docs = processed_df['lemmatizer_tokens'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "bow = CountVectorizer()\n",
    "bow_matrix = bow.fit_transform(docs)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(docs)\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(f\"Feature names:\\n{feature_names}\")\n",
    "\n",
    "dense_row = tfidf_matrix[0].todense().tolist()\n",
    "\n",
    "results = {\n",
    "    \"one_hot\": one_hot_matrix,\n",
    "    \"bow\": bow_matrix,\n",
    "    \"tfidf\": tfidf_matrix\n",
    "}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a1b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "data = processed_df['lemmatizer_tokens'].explode().dropna().tolist()\n",
    "\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1, window = 5, sg=0)\n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1,  window = 5, sg = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
